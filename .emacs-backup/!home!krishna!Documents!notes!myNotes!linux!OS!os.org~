* What happens when you switch on a computer?
- BIOS chip tells it to look in a fixed place, usually on the lowest-numbered hard disk (the boot disk) for a special program called a boot loader (under Linux the boot loader is called Grub or LILO).
- The boot loader is pulled into memory and started. The boot loader's job is to start the real operating system.
- loader does this by looking for a kernel, loading it into memory, and starting it.
- The boot loader step also lets you start one of several operating systems off different places on your disk
- Once the kernel starts, it has to look around, find the rest of the hardware, and get ready to run programs. It does this by poking
- at I/O ports — special bus addresses that are likely to have device controller cards listening at them
- The kernel doesn't poke at random; it has a lot of built-in knowledge about what it's likely to find where, and how controllers will respond if they're present. This process is called autoprobing.
- getting the kernel fully loaded and running isn't the end of the boot process; it's just the first stage (sometimes called run level 1). After this first stage, the kernel hands control to a special process called ‘init’ which spawns several housekeeping processes. (Some recent Linuxes use a different program called ‘upstart’ that does similar things)
- Init's next step is to start several daemons. A daemon is a program like a print spooler, a mail listener or a WWW server that lurks in the background, waiting for things to do.
- The next step is to prepare for users. Init starts a copy of a program called getty to watch your screen and keyboard
- Actually, nowadays it usually starts multiple copies of getty so you have several (usually 7 or 8) virtual consoles, with your screen and keyboards connected to one of them at a time.
- The next step is to start up various daemons that support networking and other services. The most important of these is your X server. X is a daemon that manages your display, keyboard, and mouse. Its main job is to produce the color pixel graphics you normally see on your screen.
- When the X server comes up, during the last part of your machine's boot process, it effectively takes over the hardware from whatever virtual console was previously in control. That's when you'll see a graphical login screen, produced for you by a program called a display manager.
- What happens when you log in?
- switch virtual consoles with a Ctrl-Shift key sequence and do a textual login, too. In that case you go through the getty instance watching that console tto call the program login.
- login name is looked up in a file called /etc/passwd
- sometimes the encrypted fields are actually kept in a second /etc/shadow file with tighter permissions; this makes password cracking harder
- The password file maps your account name to a user ID; the /etc/group file maps group names to numeric group IDs. Commands that deal with accounts and groups do the translation automatically.)
- What happens when you run programs after boot time?
- After boot time and before you run a program, you can think of your computer as containing a zoo of processes that are all waiting for something to do.
- They're all waiting on events.
- The kernel is one of these processes. It's a special one, because it controls when the other user processes can run, and it is normally the only process with direct access to the machine's hardware.
- user processes have to make requests to the kernel
- These requests are known as system calls.
- all I/O goes through the kernel
- few special user processes are allowed to slide around the kernel, usually by being given direct access to I/O ports.
- X servers are the most common example of this.
- shell is just a user process, and not a particularly special one. It waits on your keystrokes, listening (through the kernel) to the keyboard I/O port.
- As the kernel sees them, it echoes them to your virtual console or X terminal emulator.
- When the kernel sees an ‘Enter’ it passes your line of text to the shell. The shell tries to interpret those keystrokes as commands.
- Let's say you type ‘ls’
- The shell applies its built-in rules to figure out that you want to run the executable command in the file /bin/ls.
- It makes a system call asking the kernel to start /bin/ls as a new child process and give it access to the screen and keyboard through the kernel.
- Then the shell goes to sleep, waiting for ls to finish.
- When /bin/ls is done, it tells the kernel it's finished by issuing an exit system call. The kernel then wakes up the shell and tells it it can continue running.
- When you're running programs through the X server rather than a shell (that is, by choosing an application from a pull-down menu, or double-clicking a desktop icon), any of several programs associated with your X server can behave like a shell and launch the program.
- The key point is that the X server, unlike a normal shell, doesn't go to sleep while the client program is running — instead, it sits between you and the client, passing your mouse clicks and keypresses to it and fulfilling its requests to point pixels on your display.
- How do input devices and interrupts work?
- When you press or release a key, that event is signalled up the keyboard cable to raise a hardware interrupt.
- operating system's job to watch for such interrupts. For each possible kind of interrupt, there will be an interrupt handler, a part of the operating system that stashes away any data associated with them
- What the interrupt handler for your keyboard actually does is post the key value into a system area near the bottom of memory. There, it will be available for inspection when the operating system passes control to whichever program is currently supposed to be reading from the keyboard.
- disk controller using the bus to signal that a disk request has been fulfilled.
- disk raises an interrupt.
- disk interrupt handler then copies the retrieved data into memory, for later use by the program that made the request.
- Every kind of interrupt has an associated priority level.
- boot-time messages, you may see references to IRQ numbers.
- You may be aware that one of the common ways to misconfigure hardware is to have two different devices try to use the same IRQ, without understanding exactly why.
- IRQ is short for "Interrupt Request"
- The operating system needs to know at startup time which numbered interrupts each hardware device will use, so it can associate the proper handlers with each one.
- If two different devices try use the same IRQ, interrupts will sometimes get dispatched to the wrong handler. This will usually at least lock up the device, and can sometimes confuse the OS badly enough that it will flake out or crash.
- How does my computer do several things at once?
- called timesharing.
- kernel's jobs is to manage timesharing.
- a part called the scheduler which keeps information inside itself about all the other (non-kernel) processes in your zoo.
- Every 1/60th of a second, a timer goes off in the kernel, generating a clock interrupt. The scheduler stops whatever process is currently running, suspends it in place, and hands control to another process.
- If an interrupt comes in from an I/O device, the kernel effectively stops the current task, runs the interrupt handler, and then returns to the current task. A storm of high-priority interrupts can squeeze out normal processing; this misbehavior is called thrashing and is fortunately very hard to induce under modern Unixes.
- Much more often, delays are caused when the program has to wait on data from a disk drive or network connection.
- An operating system that can routinely support many simultaneous processes is called "multitasking".
- How does my computer keep processes from stepping on each other?
- memory management.
- Each process in your zoo needs its own area of memory, as a place to run its code from and keep variables and results in.
- You can think of this set as consisting of a read-only code segment (containing the process's instructions) and a writeable data segment (containing all the process's variable storage)
- The data segment is truly unique to each process, but if two processes are running the same code Unix automatically arranges for them to share a single code segment as an efficiency measure.
- Virtual memory: the simple version
- Efficiency is important, because memory is expensive.
- Sometimes you don't have enough to hold the entirety of all the programs the machine is running, especially if you are using a large program like an X server.
- To get around this, Unix uses a technique called virtual memory.
- It doesn't try to hold all the code and data for a process in memory. Instead, it keeps around only a relatively small working set; the rest of the process's state is left in a special swap space area on your hard disk.
- the size of memory was typically small relative to the size of running programs, so swapping was frequent. Memory is far less expensive nowadays and even low-end machines have quite a lot of it.
- Virtual memory: the detailed version
- your hardware actually has no fewer than five different kinds of memory in it, and the differences between them can matter a good deal when programs have to be tuned for maximum speed.
- five kinds of memory are these: processor registers, internal (or on-chip) cache, external (or off-chip) cache, main memory, and disk.
- in increasing order of access time and decreasing order of cost. Register memory is the fastest and most expensive and can be random-accessed about a billion times a second, while disk is the slowest and cheapest
- fast memory is volatile. That is, it loses its marbles when the power goes off.
- Linux and other Unixes have a feature called virtual memory. What this means is that the operating system behaves as though it has much more main memory than it actually does.
- Your actual physical main memory behaves like a set of windows or caches on a much larger "virtual" memory space, most of which at any given time is actually stored on disk in a special zone called the swap area.
- OS is moving blocks of data (called "pages") between memory and disk to maintain this illusion.
- The end result is that your virtual memory is much larger but not too much slower than real memory.
- How much slower virtual memory is than physical depends on how well the operating system's swapping algorithms match the way your programs use virtual memory.
- Fortunately, memory reads and writes that are close together in time also tend to cluster in memory space. This tendency is called locality, or more formally locality of reference
- If memory references jumped around virtual space at random, you'd typically have to do a disk read and write for each new reference and virtual memory would be as slow as a disk.
- But because programs do actually exhibit strong locality, your operating system can do relatively few swaps per reference.
- It's been found by experience that the most effective method for a broad class of memory-usage patterns is very simple; it's called LRU or the "least recently used" algorithm.
- Virtual memory is the first link in the bridge between disk and processor speeds. It's explicitly managed by the OS. But there is still a major gap between the speed of physical main memory and the speed at which a processor can access its register memory.
- The external and internal caches address this, using a technique similar to virtual memory as I've described it.
- Just as the physical main memory behaves like a set of windows or caches on the disk's swap area,
- external cache acts as windows on main memory. External cache is faster (250M accesses per sec, rather than 100M) and smaller.
- the unit of cache swapping is called a line rather than a page.
- internal cache gives us the final step-up in effective speed by caching portions of the external cache. It is faster and smaller yet — in fact, it lives right on the processor chip.
- Your programs get faster when they have stronger locality, because that makes the caching work better.
- The easiest way to make programs fast is therefore to make them small.
- If a program isn't slowed down by lots of disk I/O or waits on network events, it will usually run at the speed of the smallest cache that it will fit inside.
- The Memory Management Unit
- prevent erroneous or malicious code in one program from garbaging the data in another. To do this, it keeps a table of data and code segments.
- table is updated whenever a process either requests more memory or releases memory (the latter usually when it exits).
- Modern processor chips have MMUs built right onto them. The MMU has the special ability to put fences around areas of memory, so an out-of-bound reference will be refused and cause a special interrupt to be raised.
- a Unix message that says "Segmentation fault", "core dumped" or something similar, this is exactly what has happened; an attempt by the running program to access memory (core) outside its segment has raised a fatal interrupt.
- core dump it leaves behind is diagnostic information intended to help a programmer track it down.
- How does my computer store things in memory?
- word size of your computer.
- word size is the computer's preferred size for moving units of information around; technically it's the width of your processor's registers
- When people write about computers having bit sizes (calling them, say, "32-bit" or "64-bit" computers), this is what they mean.
- computer views your memory as a sequence of words numbered from zero up to some large value dependent on your memory size.
- Numbers
- The highest-order bit is a sign bit which makes the quantity negative, and every negative number can be obtained from the corresponding positive value by inverting all the bits and adding one.
- This is why integers on a 64-bit machine have the range -263 to 263 - 1.
- How does my computer store things on disk?
- Low-level disk and file system structure
- surface area of your disk, where it stores data, is divided up something like a dartboard — into circular tracks
- which are then pie-sliced into sectors.
- tracks near the outer edge have more area than those close to the spindle at the center of the disk
- Each sector (or disk block) has the same size, which under modern Unixes is generally 1 binary K (1024 8-bit bytes)
- Each disk block has a unique address or disk block number
- Unix divides the disk into disk partitions.
- Each partition is a continuous span of blocks that's used separately from any other partition, either as a file system or as swap space.
- The original reasons for partitions had to do with crash recovery in a world of much slower and more error-prone disks
- The lowest-numbered partition on a disk is often treated specially, as a boot partition where you can put a kernel to be booted.
- Each partition is either swap space (used to implement virtual memory) or a file system used to hold files.
- Swap-space partitions are just treated as a linear sequence of blocks.
- File systems, on the other hand, need a way to map file names to sequences of disk blocks. Because files grow, shrink, and change over time, a file's data blocks will not be a linear sequence but may be scattered all over its partition (from wherever the operating system can find a free block when it needs one)
- This scattering effect is called fragmentation.
- File names and directories
- Within each file system, the mapping from names to blocks is handled through a structure called an i-node.
- There's a pool of these things near the "bottom" (lowest-numbered blocks) of each file system
- Each i-node describes one file. File data blocks (including directories) live above the i-nodes (in higher-numbered blocks).
- Every i-node contains a list of the disk block numbers in the file it describes.
- Note that the i-node does not contain the name of the file.
- Names of files live in directory structures.
- A directory structure just maps names to i-node numbers.
- This is why, in Unix, a file can have multiple true names (or hard links); they're just multiple directory entries that happen to point to the same i-node.
- Mount points
